{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ada7d37c0b24aedb7c97a63c65ea896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_510951e7513e4a9290dd242e612e567f",
              "IPY_MODEL_1d9e64cd0e1a4010b3ce26a076776cc6",
              "IPY_MODEL_de9e81a94f444d98bfc665e8063a1f8b"
            ],
            "layout": "IPY_MODEL_5edb9eecccd946418ea3b3d0e0a9da68"
          }
        },
        "510951e7513e4a9290dd242e612e567f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_464b60069cb04ba0aaaf19de52074c57",
            "placeholder": "​",
            "style": "IPY_MODEL_331de66a912e4467ae380e0cc88f8ed8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1d9e64cd0e1a4010b3ce26a076776cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbe1d1ac2f634c18a1b8f5a704aa346f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17a6755cd87d41559219e569805601c4",
            "value": 2
          }
        },
        "de9e81a94f444d98bfc665e8063a1f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8100d262307e4da1a68d1e07e7abf82d",
            "placeholder": "​",
            "style": "IPY_MODEL_c1b621a67abf40b59c848e0c84fcd9eb",
            "value": " 2/2 [00:14&lt;00:00,  6.71s/it]"
          }
        },
        "5edb9eecccd946418ea3b3d0e0a9da68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "464b60069cb04ba0aaaf19de52074c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331de66a912e4467ae380e0cc88f8ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbe1d1ac2f634c18a1b8f5a704aa346f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a6755cd87d41559219e569805601c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8100d262307e4da1a68d1e07e7abf82d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b621a67abf40b59c848e0c84fcd9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RAG Using LlamaIndex, and HuggingFace"
      ],
      "metadata": {
        "id": "MG5x80qXCWj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install llama_index\n",
        "# !pip install llama-index-embeddings-huggingface\n",
        "# !pip install llama-index-llms-huggingface\n",
        "\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import VectorStoreIndex"
      ],
      "metadata": {
        "id": "7bGVGjEUCVyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To read the pdfs in current folder\n",
        "loader = SimpleDirectoryReader(\n",
        "    input_dir=\".\",\n",
        "    recursive=True,\n",
        "    required_exts=[\".pdf\"],\n",
        ")\n",
        "\n",
        "# Load the documents\n",
        "documents = loader.load_data()\n",
        "documents"
      ],
      "metadata": {
        "id": "7NbaMcWLK9BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load (or create) the embedding model for vector storage\n",
        "# \"BAAI/bge-small-en-v1.5\" is a small English embedding model that encodes text into a vector space for similarity-based retrieval.\n",
        "embedding_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "print(embedding_model._model.device)  # Device that the model is running on"
      ],
      "metadata": {
        "id": "-t7ovlV7CdK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746398ca-5ff1-4628-d831-62294f288a3d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates embeddings for the sentences and stores them\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    embed_model=embedding_model,\n",
        ")\n",
        "\n",
        "# Save the index in the current directory\n",
        "index.storage_context.persist(persist_dir=\"./huggingfaceembeddings\")\n"
      ],
      "metadata": {
        "id": "CmLQWn3XCgEr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the chunks\n",
        "for doc in index.docstore.docs.values():\n",
        "    print(\"Document ID:\", doc.ref_doc_id)\n",
        "    print(\"Text Chunk:\", doc.text)\n",
        "    print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "NPaN10r0Cgw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a83d340-556b-4a3e-c43f-ca1b41bad0a6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document ID: 162b19ec-44d8-4b39-bf0b-c4513a7fa1b2\n",
            "Text Chunk: Shraddha Piparia Computational Biologist, Richland, WA | +1-940-297-9424 | spiparia@health.ucsd.edu Professional Experience Postdoctoral Research Associate | 2021-Present | University of California, San Diego  • Conducted research on asthma pharmacogenetics and computational epidemiology, integrating genomic sequencing data with clinical phenotypes • Developed statistical models and machine learning pipelines to identify genetic determinants in respiratory diseases • Collaborated with multidisciplinary teams in a remote setting, contributing to high-impact publications Application Developer | 2013-2016 | Oracle India Private Limited | Telangana, India • Developed enterprise-level applications and ML-based sentiment analysis tools • Enhanced software testing processes through automated test case generation Technical Skills Programming: R, Python, C, SQL, MySQL, PostgreSQL, git/GitHub, docker, AWS ML Framework: scikit-learn, spark, TensorFlow/Keras, MXNet, pandas, NumPy AWS: Apache spark, EMR, SageMaker Bioinformatics & ML: PLINK, VCFtools, TF-IDF, NLP, One hot encoding, Principle Component Analysis, dataset assembly, exploratory analysis, data QC, disease modeling, Naive Bayes, regression models, automated workflows, high-throughput processing, endotypes, k-means/hierarchical clustering, ANOVA Genomics & Statistical Genetics: GWAS, rare variant analysis, statistical fine-mapping, genotype pattern mining, linkage disequilibrium, polygenic risk scores, functional annotation, genotype QC, pleiotropy analysis, Mendelian randomization Statistical Analysis: Regression (linear/mixed models), multivariate analysis, gene-environment interactions, power estimation, longitudinal/survival analysis (Cox, Kaplan-Meier), epidemiological study design Specialized Knowledge: pharmacogenetics and computational epidemiology Education\n",
            "==================================================\n",
            "Document ID: f2469293-efeb-4c04-a18f-e9e0fa6db6cc\n",
            "Text Chunk: PhD in Computer Science | University of North Texas | 2016-2021  MTech, Software Engineering | NIT Rourkela | 2011-2013 B.E., Computer Science | CSVTU | 2007-2011 Selected Publications 1. Piparia, S. et al. Enhancing Asthma Pharmacogenetics Through Subtype-Specific Associations. CEA, 2025 2. Piparia, S. et al. Using machine learning to improve our understanding of COVID-19 infection in children. PLoS ONE, 2023 3. Piparia, S. et al. MicroRNA-584-5p as a Key Modulator of Inhaled Corticosteroid Resistance in Asthma. In Progress\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. EMBEDDING MODEL & INDEX PERSISTENCE\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "# Load the existing index from a persisted folder\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"./huggingfaceembeddings\")\n",
        "index = load_index_from_storage(storage_context, embed_model=embedding_model)"
      ],
      "metadata": {
        "id": "ePF3c7u-bsv2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authentication for using a gated HF repo\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9ctfAZpI1W6",
        "outputId": "86238927-7be4-4bb6-e820-830c106c0b3b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `RAG` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `RAG`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. LOADING THE LOCAL LLM (Meta Llama 3.2–3B Instruct)\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "import torch\n",
        "\n",
        "device = (\n",
        "    torch.device(\"cuda\") if torch.cuda.is_available() else\n",
        "    torch.device(\"mps\") if torch.backends.mps.is_available() else\n",
        "    torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        "# Load a model and tokenizer from Hugging Face\n",
        "# \"meta-llama/Llama-3.2-3B-Instruct\" is an instruction-tuned 3B-parameter Llama model specialized\n",
        "# for generating coherent answers in response to prompts.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\").to(device)\n",
        "\n",
        "# Initialize HuggingFaceLLM - a simple LLM wrapper\n",
        "# huggingface_llm = HuggingFaceLLM(\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "# )\n",
        "# Adding generation params\n",
        "huggingface_llm = HuggingFaceLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    generate_kwargs={\n",
        "        # \"max_new_tokens\": 128,  # To cap output length\n",
        "        \"temperature\": 0.7,      # Creativity level: higher = more varied responses\n",
        "        \"top_p\": 0.9,            # Nucleus sampling threshold\n",
        "        \"top_k\": 50,             # Consider top-k tokens\n",
        "        \"do_sample\": True        # Enable sampling instead of greedy decoding\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. BUILD A QUERY ENGINE FOR RAG\n",
        "# Combine the vector store index + local LLM\n",
        "# RAG (Retrieval-Augmented Generation) means the query engine will first retrieve relevant text chunks\n",
        "# from the index, then feed them to the local LLM to produce a context-aware answer.\n",
        "query_engine = index.as_query_engine(llm=huggingface_llm)"
      ],
      "metadata": {
        "id": "PSnqetkpb6xu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4ada7d37c0b24aedb7c97a63c65ea896",
            "510951e7513e4a9290dd242e612e567f",
            "1d9e64cd0e1a4010b3ce26a076776cc6",
            "de9e81a94f444d98bfc665e8063a1f8b",
            "5edb9eecccd946418ea3b3d0e0a9da68",
            "464b60069cb04ba0aaaf19de52074c57",
            "331de66a912e4467ae380e0cc88f8ed8",
            "fbe1d1ac2f634c18a1b8f5a704aa346f",
            "17a6755cd87d41559219e569805601c4",
            "8100d262307e4da1a68d1e07e7abf82d",
            "c1b621a67abf40b59c848e0c84fcd9eb"
          ]
        },
        "outputId": "5b483edc-1bd4-48cb-9662-2e9c9bfff2d0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ada7d37c0b24aedb7c97a63c65ea896"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep llama-index\n",
        "!pip freeze | grep transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF_Nzr1fRKTI",
        "outputId": "a284138f-5926-473f-c26b-95509320c37d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llama-index==0.12.23\n",
            "llama-index-agent-openai==0.4.6\n",
            "llama-index-cli==0.4.1\n",
            "llama-index-core==0.12.23.post2\n",
            "llama-index-embeddings-huggingface==0.5.2\n",
            "llama-index-embeddings-openai==0.3.1\n",
            "llama-index-indices-managed-llama-cloud==0.6.8\n",
            "llama-index-llms-huggingface==0.4.2\n",
            "llama-index-llms-openai==0.3.25\n",
            "llama-index-multi-modal-llms-openai==0.4.3\n",
            "llama-index-program-openai==0.3.1\n",
            "llama-index-question-gen-openai==0.3.0\n",
            "llama-index-readers-file==0.4.6\n",
            "llama-index-readers-llama-parse==0.4.0\n",
            "sentence-transformers==3.4.1\n",
            "transformers==4.48.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the LLM to use\n",
        "while True:\n",
        "    question = input(\"Question: \")\n",
        "    if question.lower() == \"quit\":\n",
        "        break\n",
        "    response = query_engine.query(question)\n",
        "    print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_aplu8McDSL",
        "outputId": "376bdcd8-8112-4511-d5cf-2fb40492b770"
      },
      "execution_count": 42,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: whats the article about\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The article is about the academic and professional background of Shraddha Piparia, a Computational Biologist, including her research experience, technical skills, and education. It appears to be her resume or CV.\n",
            "Question: quit\n"
          ]
        }
      ]
    }
  ]
}